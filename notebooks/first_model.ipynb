{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd4531e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If needed (run once in a notebook cell):\n",
        "# !pip install pandas numpy requests python-dotenv scikit-learn joblib tqdm\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "from typing import Optional, Dict, Any, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from scipy.stats import spearmanr, kendalltau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "959a3b05",
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "TMDB_API_KEY = os.getenv(\"API_KEY\")\n",
        "\n",
        "if not TMDB_API_KEY:\n",
        "    raise ValueError(\"Missing API key. Put API_KEY=... in your .env file.\")\n",
        "\n",
        "ratings_path = Path(\"../inputs/ratings.csv\")\n",
        "film_ratings_df = pd.read_csv(ratings_path)\n",
        "\n",
        "film_ratings_df.head(), film_ratings_df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1745113",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = film_ratings_df.copy()\n",
        "\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
        "df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\").astype(\"Int64\")\n",
        "df[\"Rating\"] = pd.to_numeric(df[\"Rating\"], errors=\"coerce\")\n",
        "\n",
        "df = df.dropna(subset=[\"Name\", \"Rating\"])\n",
        "df = df.sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a65189e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# import pandas as pd\n",
        "# from dotenv import load_dotenv\n",
        "\n",
        "# # Load .env into environment\n",
        "# load_dotenv()\n",
        "\n",
        "# # Pull the API key from .env\n",
        "# TMDB_API_KEY = os.getenv(\"API_KEY\")\n",
        "\n",
        "# film_ratings_df = pd.read_csv(\"../inputs/ratings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1917834",
      "metadata": {},
      "outputs": [],
      "source": [
        "TMDB_BASE = \"https://api.themoviedb.org/3\"\n",
        "\n",
        "CACHE_DIR = Path(tempfile.mkdtemp(prefix=\"tmdb_cache_\"))\n",
        "\n",
        "session = requests.Session()\n",
        "session.headers.update({\"Accept\": \"application/json\"})\n",
        "\n",
        "def _cache_path(key: str) -> Path:\n",
        "    safe = re.sub(r\"[^a-zA-Z0-9._-]+\", \"_\", key)\n",
        "    return CACHE_DIR / f\"{safe}.json\"\n",
        "\n",
        "def cached_get(url: str, params: Dict[str, Any], cache_key: str, sleep_s: float = 0.25) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    GET with disk cache. sleep_s adds a small delay to be polite to the API.\n",
        "    \"\"\"\n",
        "    path = _cache_path(cache_key)\n",
        "    if path.exists():\n",
        "        return json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "    r = session.get(url, params=params, timeout=30)\n",
        "    if r.status_code != 200:\n",
        "        raise RuntimeError(f\"TMDB error {r.status_code}: {r.text[:200]}\")\n",
        "\n",
        "    data = r.json()\n",
        "    path.write_text(json.dumps(data, ensure_ascii=False), encoding=\"utf-8\")\n",
        "    time.sleep(sleep_s)\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89b8a2ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "def tmdb_search_movie(title: str, year: Optional[int] = None) -> Optional[Dict[str, Any]]:\n",
        "    params = {\"api_key\": TMDB_API_KEY, \"query\": title, \"include_adult\": \"false\"}\n",
        "    if year and not pd.isna(year):\n",
        "        params[\"year\"] = int(year)\n",
        "\n",
        "    data = cached_get(\n",
        "        f\"{TMDB_BASE}/search/movie\",\n",
        "        params=params,\n",
        "        cache_key=f\"search__{title}__{year}\"\n",
        "    )\n",
        "\n",
        "    results = data.get(\"results\", [])\n",
        "    if not results:\n",
        "        return None\n",
        "\n",
        "    # Prefer exact-ish title match if possible, else best popularity\n",
        "    title_l = title.strip().lower()\n",
        "    def score(item):\n",
        "        t = (item.get(\"title\") or \"\").lower()\n",
        "        ot = (item.get(\"original_title\") or \"\").lower()\n",
        "        exact = 2 if (t == title_l or ot == title_l) else (1 if title_l in t else 0)\n",
        "        pop = item.get(\"popularity\") or 0\n",
        "        return (exact, pop)\n",
        "\n",
        "    best = sorted(results, key=score, reverse=True)[0]\n",
        "    return best\n",
        "\n",
        "def tmdb_movie_details(movie_id: int) -> Dict[str, Any]:\n",
        "    params = {\"api_key\": TMDB_API_KEY, \"append_to_response\": \"credits,keywords\"}\n",
        "    data = cached_get(\n",
        "        f\"{TMDB_BASE}/movie/{movie_id}\",\n",
        "        params=params,\n",
        "        cache_key=f\"movie__{movie_id}__details\"\n",
        "    )\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "545e6543",
      "metadata": {},
      "outputs": [],
      "source": [
        "def safe_int(x):\n",
        "    try:\n",
        "        return int(x)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def safe_float(x):\n",
        "    try:\n",
        "        return float(x)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def extract_features_from_tmdb(details: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    genres = [g.get(\"name\") for g in details.get(\"genres\", []) if g.get(\"name\")]\n",
        "    countries = [c.get(\"iso_3166_1\") for c in details.get(\"production_countries\", []) if c.get(\"iso_3166_1\")]\n",
        "\n",
        "    overview = details.get(\"overview\") or \"\"\n",
        "\n",
        "    # keywords structure differs sometimes (movie endpoint usually returns {\"keywords\":[...]} when appended)\n",
        "    kw_block = details.get(\"keywords\") or {}\n",
        "    keywords = []\n",
        "    if isinstance(kw_block, dict):\n",
        "        keywords = [k.get(\"name\") for k in kw_block.get(\"keywords\", []) if k.get(\"name\")]\n",
        "\n",
        "    credits = details.get(\"credits\") or {}\n",
        "    crew = credits.get(\"crew\", []) if isinstance(credits, dict) else []\n",
        "    cast = credits.get(\"cast\", []) if isinstance(credits, dict) else []\n",
        "\n",
        "    directors = [p.get(\"name\") for p in crew if p.get(\"job\") == \"Director\" and p.get(\"name\")]\n",
        "    director = directors[0] if directors else \"\"\n",
        "\n",
        "    top_cast = [p.get(\"name\") for p in cast[:5] if p.get(\"name\")]\n",
        "\n",
        "    # Combine “people” into a text field so TF-IDF can learn patterns\n",
        "    people_text = \" \".join([director] + top_cast).strip()\n",
        "\n",
        "    return {\n",
        "        \"tmdb_id\": details.get(\"id\"),\n",
        "        \"title_tmdb\": details.get(\"title\"),\n",
        "        \"release_date\": details.get(\"release_date\"),\n",
        "        \"release_year_tmdb\": safe_int((details.get(\"release_date\") or \"\")[:4]) if details.get(\"release_date\") else np.nan,\n",
        "\n",
        "        \"runtime\": safe_float(details.get(\"runtime\")),\n",
        "        \"budget\": safe_float(details.get(\"budget\")),\n",
        "        \"revenue\": safe_float(details.get(\"revenue\")),\n",
        "\n",
        "        \"popularity\": safe_float(details.get(\"popularity\")),\n",
        "        \"vote_average\": safe_float(details.get(\"vote_average\")),\n",
        "        \"vote_count\": safe_float(details.get(\"vote_count\")),\n",
        "\n",
        "        \"original_language\": details.get(\"original_language\") or \"\",\n",
        "        \"genres\": \"|\".join([g for g in genres if g]) if genres else \"\",\n",
        "        \"production_countries\": \"|\".join([c for c in countries if c]) if countries else \"\",\n",
        "        \"keywords\": \" \".join([k for k in keywords if k]) if keywords else \"\",\n",
        "\n",
        "        \"overview\": overview,\n",
        "        \"people_text\": people_text,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "343f4c88",
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = []\n",
        "missing = []\n",
        "\n",
        "for _, r in tqdm(df.iterrows(), total=len(df)):\n",
        "    title = str(r[\"Name\"])\n",
        "    year = int(r[\"Year\"]) if not pd.isna(r[\"Year\"]) else None\n",
        "\n",
        "    search = tmdb_search_movie(title, year=year)\n",
        "    if not search:\n",
        "        missing.append((title, year))\n",
        "        continue\n",
        "\n",
        "    movie_id = search.get(\"id\")\n",
        "    if not movie_id:\n",
        "        missing.append((title, year))\n",
        "        continue\n",
        "\n",
        "    details = tmdb_movie_details(movie_id)\n",
        "    feats = extract_features_from_tmdb(details)\n",
        "\n",
        "    out = {\n",
        "        \"Date\": r[\"Date\"],\n",
        "        \"Name\": title,\n",
        "        \"Year\": year,\n",
        "        \"Letterboxd URI\": r.get(\"Letterboxd URI\", \"\"),\n",
        "        \"Rating\": float(r[\"Rating\"]),\n",
        "        **feats,\n",
        "    }\n",
        "    rows.append(out)\n",
        "\n",
        "features_df = pd.DataFrame(rows)\n",
        "features_df.shape, features_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d0c73b",
      "metadata": {},
      "outputs": [],
      "source": [
        "print((missing[:20], len(missing))) # these are just tv shows \n",
        "features_df.to_csv(\"./ratings_with_tmdb_features.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dda510e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = features_df.copy()\n",
        "\n",
        "# Derived numeric features\n",
        "data[\"log_budget\"] = np.log1p(data[\"budget\"].fillna(0))\n",
        "data[\"log_revenue\"] = np.log1p(data[\"revenue\"].fillna(0))\n",
        "data[\"log_vote_count\"] = np.log1p(data[\"vote_count\"].fillna(0))\n",
        "data[\"genres_count\"] = data[\"genres\"].fillna(\"\").apply(lambda s: 0 if s == \"\" else len(s.split(\"|\")))\n",
        "data[\"countries_count\"] = data[\"production_countries\"].fillna(\"\").apply(lambda s: 0 if s == \"\" else len(s.split(\"|\")))\n",
        "\n",
        "# Fill missing for text fields\n",
        "for col in [\"overview\", \"keywords\", \"people_text\", \"genres\", \"production_countries\", \"original_language\"]:\n",
        "    data[col] = data[col].fillna(\"\")\n",
        "\n",
        "# Target\n",
        "y = data[\"Rating\"].astype(float)\n",
        "\n",
        "data.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f2aa12",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data.sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "# Use last 20% as holdout\n",
        "cut = int(len(data) * 0.8)\n",
        "train_df = data.iloc[:cut].copy()\n",
        "test_df  = data.iloc[cut:].copy()\n",
        "\n",
        "X_train = train_df\n",
        "y_train = train_df[\"Rating\"].astype(float)\n",
        "\n",
        "X_test = test_df\n",
        "y_test = test_df[\"Rating\"].astype(float)\n",
        "\n",
        "len(train_df), len(test_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22905f6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "text_overview = TfidfVectorizer(\n",
        "    max_features=2500,\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2\n",
        ")\n",
        "\n",
        "text_keywords = TfidfVectorizer(\n",
        "    max_features=1500,\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2\n",
        ")\n",
        "\n",
        "text_people = TfidfVectorizer(\n",
        "    max_features=1500,\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2\n",
        ")\n",
        "\n",
        "# Treat pipe-separated as space-separated tokens, then TF-IDF\n",
        "pipe_as_text = TfidfVectorizer(\n",
        "    max_features=800,\n",
        "    tokenizer=lambda s: s.split(\"|\"),\n",
        "    preprocessor=lambda s: s,\n",
        "    token_pattern=None\n",
        ")\n",
        "\n",
        "numeric_features = [\n",
        "    \"runtime\", \"popularity\", \"vote_average\", \"vote_count\",\n",
        "    \"log_budget\", \"log_revenue\", \"log_vote_count\",\n",
        "    \"genres_count\", \"countries_count\",\n",
        "    \"release_year_tmdb\",\n",
        "]\n",
        "\n",
        "categorical_features = [\"original_language\"]\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", Pipeline(steps=[\n",
        "            (\"impute\", StandardScaler(with_mean=False)),  # works with sparse output too\n",
        "        ]), numeric_features),\n",
        "\n",
        "        (\"lang\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
        "\n",
        "        (\"overview\", text_overview, \"overview\"),\n",
        "        (\"keywords\", text_keywords, \"keywords\"),\n",
        "        (\"people\", text_people, \"people_text\"),\n",
        "        (\"genres\", pipe_as_text, \"genres\"),\n",
        "        (\"countries\", pipe_as_text, \"production_countries\"),\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        "    sparse_threshold=0.3,\n",
        ")\n",
        "\n",
        "model = Ridge(alpha=2.0, random_state=42)\n",
        "\n",
        "pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"model\", model)\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7f75f69",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d14fc3da",
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = pipe.predict(X_test)\n",
        "pred_clipped = np.clip(pred, 0.5, 5.0)\n",
        "\n",
        "mae = mean_absolute_error(y_test, pred_clipped)\n",
        "rmse = mean_squared_error(y_test, pred_clipped)\n",
        "r2 = r2_score(y_test, pred_clipped)\n",
        "\n",
        "print((mae, rmse, r2))\n",
        "\n",
        "eval_df = test_df[[\"Date\", \"Name\", \"Year\", \"Rating\"]].copy()\n",
        "eval_df[\"pred\"] = pred_clipped\n",
        "eval_df[\"err\"] = eval_df[\"pred\"] - eval_df[\"Rating\"]\n",
        "eval_df.sort_values(\"err\").head(10), eval_df.sort_values(\"err\").tail(10)\n",
        "\n",
        "\n",
        "\n",
        "spearman = spearmanr(y_test, pred_clipped).correlation\n",
        "print(spearman)\n",
        "\n",
        "from scipy.stats import kendalltau\n",
        "\n",
        "kendall = kendalltau(y_test, pred_clipped).correlation\n",
        "print(kendall)\n",
        "\n",
        "\n",
        "joblib.dump(pipe, \"./letterboxd_tmdb_rating_model.joblib\")\n",
        "print(\"Saved: ./letterboxd_tmdb_rating_model.joblib\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9fc9c5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_snapped = np.round(pred_clipped * 2) / 2\n",
        "\n",
        "exact_match_rate = (pred_snapped == y_test).mean()\n",
        "within_half_star = (np.abs(pred_snapped - y_test) <= 0.5).mean()\n",
        "\n",
        "exact_match_rate, within_half_star\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cf48503",
      "metadata": {},
      "outputs": [],
      "source": [
        "bucket_eval = (\n",
        "    eval_df\n",
        "    .assign(abs_err=lambda d: np.abs(d[\"err\"]))\n",
        "    .groupby(\"Rating\")[\"abs_err\"]\n",
        "    .mean()\n",
        ")\n",
        "\n",
        "bucket_eval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57d56036",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "film-recommendations",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
